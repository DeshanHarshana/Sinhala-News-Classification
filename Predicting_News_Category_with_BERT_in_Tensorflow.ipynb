{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["wEhTK6Sypwqr","HAssmxxJp0yM","kyzTzLpyqJUf","pmFYvkylMwXn","ccp5trMwRtmr","_vrumsg9uygH"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dCpvgG0vwXAZ"},"source":["#Predicting News Category With BERT IN Tensorflow\n","\n","---\n","\n","Bidirectional Encoder Representations from Transformers or BERT for short is a very popular NLP model from Google known for producing state-of-the-art results in a wide variety of NLP tasks.\n","\n","The importance of Natural Language Processing(NLP) is profound in the Artificial Intelligence domain. The most abundant data in the world today is in the form of texts and having a powerful text processing system is critical and is more than  just a necessity.\n","\n","In this article we look at implementing a multi-class classification using the state-of-the-art model, BERT.\n","\n","---\n","\n","#####Pre-Requisites:\n","\n","#####An Understanding of BERT\n","---\n","\n","##About Dataset\n","\n","For this article, we will use MachineHack’s Predict The News Category Hackathon data. The data  consists of a collection of news articles which are categorized into four sections. The features of the datasets are as follows:\n","\n","Size of training set: 7,628 records\n","Size of test set: 2,748 records\n","\n","FEATURES:\n","\n","STORY:  A part of the main content of the article to be published as a piece of news.\n","SECTION: The genre/category the STORY falls in.\n","\n","There are four distinct sections where each story may fall in to. The Sections are labelled as follows :\n","Politics: 0\n","Technology: 1\n","Entertainment: 2\n","Business: 3\n"]},{"cell_type":"markdown","metadata":{"id":"wEhTK6Sypwqr"},"source":["##Mounting Google Drive\n","\n","---\n","Here I have uploaded the dataset in to my Google Drive folder. To access the datasets we must first mount the drive in google colab. Type in and enter the following code to authenticate and mount your Google drive on to colab.\n","\n"]},{"cell_type":"code","metadata":{"id":"5w8YSdcFPA_r","outputId":"a3a318a9-c3d3-4bdc-9095-0cc77d2578fa","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount(\"/GD\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /GD; to attempt to forcibly remount, call drive.mount(\"/GD\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HAssmxxJp0yM"},"source":["## Importing Necessary Libraries"]},{"cell_type":"code","metadata":{"id":"hsZvic2YxnTz","outputId":"124ac0c4-df1e-40f4-a29f-68995302ac1e","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import pandas as pd\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from datetime import datetime\n","from sklearn.model_selection import train_test_split\n","import os\n","\n","print(\"tensorflow version : \", tf.__version__)\n","print(\"tensorflow_hub version : \", hub.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensorflow version :  1.15.0\n","tensorflow_hub version :  0.7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jviywGyWyKsA","outputId":"3d8b4c8c-0ad5-4cdf-d6be-55c336a82b1f","colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["#Installing BERT module\n","!pip install bert-tensorflow"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting bert-tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n","\r\u001b[K     |████▉                           | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.3MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n","Installing collected packages: bert-tensorflow\n","Successfully installed bert-tensorflow-1.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hhbGEfwgdEtw","outputId":"6f199f26-93b3-4580-f9b6-456f88989533","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#Importing BERT modules\n","import bert\n","from bert import run_classifier\n","from bert import optimization\n","from bert import tokenization"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kyzTzLpyqJUf"},"source":["##Setting The Output Directory\n","---\n","While fine-tuning the model, we will save the training checkpoints and the model in an output directory so that we can use the trained model for our predictions later.\n","\n","The following code block sets an output directory :\n","\n"]},{"cell_type":"code","metadata":{"id":"US_EAnICvP7f","outputId":"ff060b68-a834-4e85-bd9f-54c2760c04e8","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Set the output directory for saving model file\n","OUTPUT_DIR = '/GD/My Drive/Colab Notebooks/BERT/bert_news_category'\n","\n","#@markdown Whether or not to clear/delete the directory and create a new one\n","DO_DELETE = False #@param {type:\"boolean\"}\n","\n","if DO_DELETE:\n","  try:\n","    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n","  except:\n","    pass\n","\n","tf.gfile.MakeDirs(OUTPUT_DIR)\n","print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["***** Model output directory: /GD/My Drive/Colab Notebooks/BERT/bert_news_category *****\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pmFYvkylMwXn"},"source":["##Loading The Data\n","---\n","We will now load the data from a Google Drive directory and will also split the training set in to training and validation sets.\n"]},{"cell_type":"code","metadata":{"id":"VIsetAbCam6y"},"source":["train = pd.read_excel(\"/GD/My Drive/Colab Notebooks/News_category/Datasets/Data_Train.xlsx\")\n","test = pd.read_excel(\"/GD/My Drive/Colab Notebooks/News_category/Datasets/Data_Test.xlsx\")\n","\n","from sklearn.model_selection import train_test_split\n","\n","train, val =  train_test_split(train, test_size = 0.2, random_state = 100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BP-kcaJ7bGza","outputId":"b090eaa4-eba6-4e86-8006-d4926d6d67ce","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["#Training set sample\n","train.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>STORY</th>\n","      <th>SECTION</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4359</th>\n","      <td>Oil prices extended its rally to a five-month ...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3520</th>\n","      <td>Apple shares have risen more than 10% in March...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4530</th>\n","      <td>The veteran actor plays a retired army officer...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6945</th>\n","      <td>BuzzFeed could use a boost. Two years ago, the...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2298</th>\n","      <td>Bigg Boss Tamil 2 fame Mahat Raghavendra on We...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                  STORY  SECTION\n","4359  Oil prices extended its rally to a five-month ...        3\n","3520  Apple shares have risen more than 10% in March...        1\n","4530  The veteran actor plays a retired army officer...        2\n","6945  BuzzFeed could use a boost. Two years ago, the...        1\n","2298  Bigg Boss Tamil 2 fame Mahat Raghavendra on We...        2"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"i4g40DO4bJCR","outputId":"7d5e1cf5-4ed9-4815-dd32-224fc048212b","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["#Test set sample\n","test.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>STORY</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2019 will see gadgets like gaming smartphones ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>It has also unleashed a wave of changes in the...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>It can be confusing to pick the right smartpho...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The mobile application is integrated with a da...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>We have rounded up some of the gadgets that sh...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               STORY\n","0  2019 will see gadgets like gaming smartphones ...\n","1  It has also unleashed a wave of changes in the...\n","2  It can be confusing to pick the right smartpho...\n","3  The mobile application is integrated with a da...\n","4  We have rounded up some of the gadgets that sh..."]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"e_rukDBlbvCj","outputId":"50f8f587-97cd-457f-b151-cf2b33adbc9d","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(\"Training Set Shape :\", train.shape)\n","print(\"Validation Set Shape :\", val.shape)\n","print(\"Test Set Shape :\", test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Set Shape : (6102, 2)\n","Validation Set Shape : (1526, 2)\n","Test Set Shape : (2748, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k428NfLdcAqR","outputId":"14f3de25-f919-451f-c44f-9b278be84590","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Features in the dataset\n","train.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['STORY', 'SECTION'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"U9IwgBb-cOm3","outputId":"6b46ab7b-d27a-41ca-9f75-b17e36136464","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#unique classes\n","train['SECTION'].unique()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3, 1, 2, 0])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"kToy7D-TSrn_","colab":{"base_uri":"https://localhost:8080/","height":279},"outputId":"97bb564f-2c73-489b-db7b-52591588de53"},"source":["#Distribution of classes\n","train['SECTION'].value_counts().plot(kind = 'bar')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7ff5921f9ba8>"]},"metadata":{"tags":[]},"execution_count":12},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX0AAAD1CAYAAAC87SVQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7B1JasToS1IjRl+SGjH6ktSI0ZekRv4XHggHDSdX50IAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"IuMOGwFui4it"},"source":["DATA_COLUMN = 'STORY'\n","LABEL_COLUMN = 'SECTION'\n","# The list containing all the classes (train['SECTION'].unique())\n","label_list = [0, 1, 2, 3]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V399W0rqNJ-Z"},"source":["## Data Preprocessing\n","\n","BERT model accept only a specific type of input and the datasets are usually structured to have have the following four features:\n","\n","* guid : A unique id that represents an observation.\n","* text_a : The text we need to classify into given categories\n","* text_b: It is used when we're training a model to understand the relationship between sentences and it does not apply for classification problems.\n","* label: It consists of the labels or classes or categories that a given text belongs to.\n"," \n","In our dataset we have text_a and label. The following code block will create objects for each of the above mentioned features for all the records in our dataset using the InputExample class provided in the BERT library.\n"]},{"cell_type":"code","metadata":{"id":"p9gEt5SmM6i6"},"source":["train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n","                                                                   text_a = x[DATA_COLUMN], \n","                                                                   text_b = None, \n","                                                                   label = x[LABEL_COLUMN]), axis = 1)\n","\n","val_InputExamples = val.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n","                                                                   text_a = x[DATA_COLUMN], \n","                                                                   text_b = None, \n","                                                                   label = x[LABEL_COLUMN]), axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K50MFQXXWFJM","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"d4636ef7-9099-410d-c393-ddb4f713c255"},"source":["train_InputExamples"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4359    <bert.run_classifier.InputExample object at 0x...\n","3520    <bert.run_classifier.InputExample object at 0x...\n","4530    <bert.run_classifier.InputExample object at 0x...\n","6945    <bert.run_classifier.InputExample object at 0x...\n","2298    <bert.run_classifier.InputExample object at 0x...\n","                              ...                        \n","79      <bert.run_classifier.InputExample object at 0x...\n","3927    <bert.run_classifier.InputExample object at 0x...\n","5955    <bert.run_classifier.InputExample object at 0x...\n","6936    <bert.run_classifier.InputExample object at 0x...\n","5640    <bert.run_classifier.InputExample object at 0x...\n","Length: 6102, dtype: object"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"a7UC2dnVRsoZ","outputId":"105924ba-0e83-4f65-f7c9-ea7089866043","colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n","print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n","print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n","print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Row 0 - guid of training set :  None\n","\n","__________\n","Row 0 - text_a of training set :  Oil prices extended its rally to a five-month high as conflict in Libya increased the risk of new supply outages\n","\n","\n","Indian rupee today weakened marginally against US dollar, tracking losses in other Asian currencies as traders awaited further details on a possible US-China trade deal. Higher crude oil prices also dampened sentiment. At 9.15 am, the rupee was trading at 69.46 a dollar, down 0.34% from its previous close of 69.23. The home currency opened at 69.34 a dollar.\n","\n","__________\n","Row 0 - text_b of training set :  None\n","\n","__________\n","Row 0 - label of training set :  3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qMWiDtpyQSoU"},"source":["We will now get down to business with the pretrained BERT.  In this example we will use the ```bert_uncased_L-12_H-768_A-12/1``` model. To check all available versions click [here](https://tfhub.dev/s?network-architecture=transformer&publisher=google).\n","\n","We will be using the vocab.txt file in the model to map the words in the dataset to indexes. Also the loaded BERT model is trained on uncased/lowercase data and hence the data we feed to train the model should also be of lowercase.\n","\n","---\n","\n","The following code block loads the pre-trained BERT model and initializers a tokenizer object for tokenizing the texts.\n"]},{"cell_type":"code","metadata":{"id":"IhJSe0QHNG7U","outputId":"5591de28-d634-4e39-df73-6576d7f4cfb3","colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["\n","# This is a path to an uncased (all lowercase) version of BERT\n","BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n","\n","def create_tokenizer_from_hub_module():\n","  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n","  with tf.Graph().as_default():\n","    bert_module = hub.Module(BERT_MODEL_HUB)\n","    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n","    with tf.Session() as sess:\n","      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n","                                            tokenization_info[\"do_lower_case\"]])\n","      \n","  return bert.tokenization.FullTokenizer(\n","      vocab_file=vocab_file, do_lower_case=do_lower_case)\n","\n","tokenizer = create_tokenizer_from_hub_module()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"t3T3jSpjSxmd","outputId":"bc437cfd-4c1a-4384-b080-0881c99eb34f","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["#Here is what the tokenised sample of the first training set observation looks like\n","print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['oil', 'prices', 'extended', 'its', 'rally', 'to', 'a', 'five', '-', 'month', 'high', 'as', 'conflict', 'in', 'libya', 'increased', 'the', 'risk', 'of', 'new', 'supply', 'out', '##ages', 'indian', 'ru', '##pee', 'today', 'weakened', 'marginal', '##ly', 'against', 'us', 'dollar', ',', 'tracking', 'losses', 'in', 'other', 'asian', 'cu', '##rre', '##ncies', 'as', 'traders', 'awaited', 'further', 'details', 'on', 'a', 'possible', 'us', '-', 'china', 'trade', 'deal', '.', 'higher', 'crude', 'oil', 'prices', 'also', 'damp', '##ened', 'sentiment', '.', 'at', '9', '.', '15', 'am', ',', 'the', 'ru', '##pee', 'was', 'trading', 'at', '69', '.', '46', 'a', 'dollar', ',', 'down', '0', '.', '34', '%', 'from', 'its', 'previous', 'close', 'of', '69', '.', '23', '.', 'the', 'home', 'currency', 'opened', 'at', '69', '.', '34', 'a', 'dollar', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mtvrR5eusZPO"},"source":["We will now format out text in to input features which the BERT model expects. We will also set a sequence length which will be the length of the input features."]},{"cell_type":"code","metadata":{"id":"LL5W8gEGRTAf"},"source":["# We'll set sequences to be at most 128 tokens long.\n","MAX_SEQ_LENGTH = 128\n","\n","# Convert our train and validation features to InputFeatures that BERT understands.\n","train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","\n","val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZEmm8KEUX3F"},"source":["#Example on first observation in the training set\n","print(\"Sentence : \", train_InputExamples.iloc[0].text_a)\n","print(\"-\"*30)\n","print(\"Tokens : \", tokenizer.tokenize(train_InputExamples.iloc[0].text_a))\n","print(\"-\"*30)\n","print(\"Input IDs : \", train_features[0].input_ids)\n","print(\"-\"*30)\n","print(\"Input Masks : \", train_features[0].input_mask)\n","print(\"-\"*30)\n","print(\"Segment IDs : \", train_features[0].segment_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ccp5trMwRtmr"},"source":["##Creating A Multi-Class Classifier Model\n"]},{"cell_type":"code","metadata":{"id":"6o2a5ZIvRcJq"},"source":["def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n","                 num_labels):\n","  \n","  bert_module = hub.Module(\n","      BERT_MODEL_HUB,\n","      trainable=True)\n","  bert_inputs = dict(\n","      input_ids=input_ids,\n","      input_mask=input_mask,\n","      segment_ids=segment_ids)\n","  bert_outputs = bert_module(\n","      inputs=bert_inputs,\n","      signature=\"tokens\",\n","      as_dict=True)\n","\n","  # Use \"pooled_output\" for classification tasks on an entire sentence.\n","  # Use \"sequence_outputs\" for token-level output.\n","  output_layer = bert_outputs[\"pooled_output\"]\n","\n","  hidden_size = output_layer.shape[-1].value\n","\n","  # Create our own layer to tune for politeness data.\n","  output_weights = tf.get_variable(\n","      \"output_weights\", [num_labels, hidden_size],\n","      initializer=tf.truncated_normal_initializer(stddev=0.02))\n","\n","  output_bias = tf.get_variable(\n","      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n","\n","  with tf.variable_scope(\"loss\"):\n","\n","    # Dropout helps prevent overfitting\n","    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n","\n","    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n","    logits = tf.nn.bias_add(logits, output_bias)\n","    log_probs = tf.nn.log_softmax(logits, axis=-1)\n","\n","    # Convert labels into one-hot encoding\n","    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n","\n","    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n","    # If we're predicting, we want predicted labels and the probabiltiies.\n","    if is_predicting:\n","      return (predicted_labels, log_probs)\n","\n","    # If we're train/eval, compute loss between predicted and actual label\n","    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n","    loss = tf.reduce_mean(per_example_loss)\n","    return (loss, predicted_labels, log_probs)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FnH-AnOQ9KKW"},"source":["#A function that adapts our model to work for training, evaluation, and prediction.\n","\n","# model_fn_builder actually creates our model function\n","# using the passed parameters for num_labels, learning_rate, etc.\n","def model_fn_builder(num_labels, learning_rate, num_train_steps,\n","                     num_warmup_steps):\n","  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n","  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n","    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n","\n","    input_ids = features[\"input_ids\"]\n","    input_mask = features[\"input_mask\"]\n","    segment_ids = features[\"segment_ids\"]\n","    label_ids = features[\"label_ids\"]\n","\n","    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n","    \n","    # TRAIN and EVAL\n","    if not is_predicting:\n","\n","      (loss, predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      train_op = bert.optimization.create_optimizer(\n","          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n","\n","      # Calculate evaluation metrics. \n","      def metric_fn(label_ids, predicted_labels):\n","        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n","        true_pos = tf.metrics.true_positives(\n","            label_ids,\n","            predicted_labels)\n","        true_neg = tf.metrics.true_negatives(\n","            label_ids,\n","            predicted_labels)   \n","        false_pos = tf.metrics.false_positives(\n","            label_ids,\n","            predicted_labels)  \n","        false_neg = tf.metrics.false_negatives(\n","            label_ids,\n","            predicted_labels)\n","        \n","        return {\n","            \"eval_accuracy\": accuracy,\n","            \"true_positives\": true_pos,\n","            \"true_negatives\": true_neg,\n","            \"false_positives\": false_pos,\n","            \"false_negatives\": false_neg\n","            }\n","\n","      eval_metrics = metric_fn(label_ids, predicted_labels)\n","\n","      if mode == tf.estimator.ModeKeys.TRAIN:\n","        return tf.estimator.EstimatorSpec(mode=mode,\n","          loss=loss,\n","          train_op=train_op)\n","      else:\n","          return tf.estimator.EstimatorSpec(mode=mode,\n","            loss=loss,\n","            eval_metric_ops=eval_metrics)\n","    else:\n","      (predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      predictions = {\n","          'probabilities': log_probs,\n","          'labels': predicted_labels\n","      }\n","      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n","\n","  # Return the actual model function in the closure\n","  return model_fn\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OjwJ4bTeWXD8"},"source":["# Compute train and warmup steps from batch size\n","# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n","BATCH_SIZE = 32\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 3.0\n","# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n","WARMUP_PROPORTION = 0.1\n","# Model configs\n","SAVE_CHECKPOINTS_STEPS = 300\n","SAVE_SUMMARY_STEPS = 100\n","\n","# Compute train and warmup steps from batch size\n","num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n","\n","# Specify output directory and number of checkpoint steps to save\n","run_config = tf.estimator.RunConfig(\n","    model_dir=OUTPUT_DIR,\n","    save_summary_steps=SAVE_SUMMARY_STEPS,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n","\n","# Specify output directory and number of checkpoint steps to save\n","run_config = tf.estimator.RunConfig(\n","    model_dir=OUTPUT_DIR,\n","    save_summary_steps=SAVE_SUMMARY_STEPS,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_WebpS1X97v","outputId":"917d1322-1812-42d6-901c-46798a121652","colab":{"base_uri":"https://localhost:8080/","height":275}},"source":["#Initializing the model and the estimator\n","model_fn = model_fn_builder(\n","  num_labels=len(label_list),\n","  learning_rate=LEARNING_RATE,\n","  num_train_steps=num_train_steps,\n","  num_warmup_steps=num_warmup_steps)\n","\n","estimator = tf.estimator.Estimator(\n","  model_fn=model_fn,\n","  config=run_config,\n","  params={\"batch_size\": BATCH_SIZE})\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': '/GD/My Drive/Colab Notebooks/BERT/bert_news_category', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff5448672b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': '/GD/My Drive/Colab Notebooks/BERT/bert_news_category', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff5448672b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"NOO3RfG1DYLo"},"source":["we will now create an input builder function that takes our training feature set (`train_features`) and produces a generator. This is a pretty standard design pattern for working with Tensorflow [Estimators](https://www.tensorflow.org/guide/estimators)."]},{"cell_type":"code","metadata":{"id":"1Pv2bAlOX_-K"},"source":["# Create an input function for training. drop_remainder = True for using TPUs.\n","train_input_fn = bert.run_classifier.input_fn_builder(\n","    features=train_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=True,\n","    drop_remainder=False)\n","\n","# Create an input function for validating. drop_remainder = True for using TPUs.\n","val_input_fn = run_classifier.input_fn_builder(\n","    features=val_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=False,\n","    drop_remainder=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_vrumsg9uygH"},"source":["##Training & Evaluating"]},{"cell_type":"code","metadata":{"id":"nucD4gluYJmK","outputId":"7793bdd3-8be5-4f9c-9c70-de03397186ad","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#Training the model\n","print(f'Beginning Training!')\n","current_time = datetime.now()\n","estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","print(\"Training took time \", datetime.now() - current_time)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Beginning Training!\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-22-bdfb628bf45b>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-22-bdfb628bf45b>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into /GD/My Drive/Colab Notebooks/BERT/bert_news_category/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into /GD/My Drive/Colab Notebooks/BERT/bert_news_category/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 1.671329, step = 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 1.671329, step = 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.579778\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.579778\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.02809212, step = 100 (172.482 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.02809212, step = 100 (172.482 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.640514\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.640514\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0046886336, step = 200 (156.124 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0046886336, step = 200 (156.124 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 300 into /GD/My Drive/Colab Notebooks/BERT/bert_news_category/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 300 into /GD/My Drive/Colab Notebooks/BERT/bert_news_category/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.614066\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.614066\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0064441273, step = 300 (162.853 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0064441273, step = 300 (162.853 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.640734\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.640734\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0016644242, step = 400 (156.068 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0016644242, step = 400 (156.068 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.639597\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 0.639597\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0014373187, step = 500 (156.353 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.0014373187, step = 500 (156.353 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 572 into /GD/My Drive/Colab Notebooks/BERT/bert_news_category/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 572 into /GD/My Drive/Colab Notebooks/BERT/bert_news_category/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Loss for final step: 0.013614067.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Loss for final step: 0.013614067.\n"],"name":"stderr"},{"output_type":"stream","text":["Training took time  0:16:15.354629\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PPVEXhNjYXC-","outputId":"23deac72-c825-46a9-835b-721bbdef57e8","colab":{"base_uri":"https://localhost:8080/","height":564}},"source":["#Evaluating the model with Validation set\n","estimator.evaluate(input_fn=val_input_fn, steps=None)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2019-11-14T11:32:13Z\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2019-11-14T11:32:13Z\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /GD/My Drive/Colab Notebooks/BERT/bert_news_category/model.ckpt-572\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /GD/My Drive/Colab Notebooks/BERT/bert_news_category/model.ckpt-572\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2019-11-14-11:32:46\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2019-11-14-11:32:46\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 572: eval_accuracy = 0.98689383, false_negatives = 8.0, false_positives = 7.0, global_step = 572, loss = 0.060107384, true_negatives = 338.0, true_positives = 1173.0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 572: eval_accuracy = 0.98689383, false_negatives = 8.0, false_positives = 7.0, global_step = 572, loss = 0.060107384, true_negatives = 338.0, true_positives = 1173.0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 572: /GD/My Drive/Colab Notebooks/BERT/bert_news_category/model.ckpt-572\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 572: /GD/My Drive/Colab Notebooks/BERT/bert_news_category/model.ckpt-572\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["{'eval_accuracy': 0.98689383,\n"," 'false_negatives': 8.0,\n"," 'false_positives': 7.0,\n"," 'global_step': 572,\n"," 'loss': 0.060107384,\n"," 'true_negatives': 338.0,\n"," 'true_positives': 1173.0}"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"dTF8Om8f7S7e"},"source":["##Vola !! We got an evaluation accuracy of 98% on the validation set by just having trained the model for 3 epochs and a few hundred steps."]},{"cell_type":"markdown","metadata":{"id":"_6f9Rlhrupt6"},"source":["##Predicting For Test Set"]},{"cell_type":"code","metadata":{"id":"OsrbTD2EJTVl"},"source":["\"\"\"Politics: 0\n","Technology: 1\n","Entertainment: 2\n","Business: 3\"\"\"\n","\n","# A method to get predictions\n","def getPrediction(in_sentences):\n","  #A list to map the actual labels to the predictions\n","  labels = [\"Politics\", \"Technology\",\"Entertainment\",\"Business\"]\n","\n","  #Transforming the test data into BERT accepted form\n","  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n","  \n","  #Creating input features for Test data\n","  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","\n","  #Predicting the classes \n","  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n","  predictions = estimator.predict(predict_input_fn)\n","  return [(sentence, prediction['probabilities'],prediction['labels'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-thbodgih_VJ"},"source":["pred_sentences = list(test['STORY'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrZmvZySKQTm"},"source":["predictions = getPrediction(pred_sentences)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvWtkufBoCyp"},"source":["predictions[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ERkTE8-7oQLZ"},"source":["enc_labels = []\n","act_labels = []\n","for i in range(len(predictions)):\n","  enc_labels.append(predictions[i][2])\n","  act_labels.append(predictions[i][3])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ADAUcUuwo1I"},"source":["pd.DataFrame(enc_labels, columns = ['SECTION']).to_excel('/GD/My Drive/Colab Notebooks/BERT/submission_bert.xlsx', index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2mRe3Jrlt8RV"},"source":["## Random Tester"]},{"cell_type":"code","metadata":{"id":"Y_yYnS-nt6ZU"},"source":["#Classifying random sentences\n","tests = getPrediction(['Mr.Modi is the Indian Prime Minister',\n","                       'Gaming machines are powered by efficient micro processores and GPUs',\n","                       'That HBO TV series is really good',\n","                       'A trillion dollar economy '\n","                       ])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bjFLQTqAt6WG"},"source":["tests"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qi5MqgDRhZno"},"source":["#Reference:\n","Most of the code has been taken from the following resource:\n","\n","* https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb\n","\n"]}]}